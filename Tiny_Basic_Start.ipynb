{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91ad8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st 5 lines in the datset \n",
      "        paper_id                                              title primary_category               categories year_month                              singularized_abstract\n",
      "0  2301.02657v1  TarViS: A Unified Approach for Target-based Vi...            cs.CV        cs.CV cs.AI cs.LG    2023-01  general domain video segmentation currently fr...\n",
      "1  2301.02642v1  Triple-stream Deep Metric Learning of Great Ap...            cs.CV        cs.CV cs.AI cs.LG    2023-01  propose first metric learning system recogniti...\n",
      "2  2301.02610v1              Feedback-Gated Rectified Linear Units            cs.NE              cs.NE cs.AI    2023-01  Feedback connection play prominent role human ...\n",
      "3  2301.02593v1  Multi-Agent Reinforcement Learning for Fast-Ti...            cs.MA  cs.MA cs.AI cs.LG cs.SY    2023-01  integrate high amount renewable energy resourc...\n",
      "4  2301.02561v1  Multi-Vehicle Trajectory Prediction at Interse...            cs.RO              cs.RO cs.AI    2023-01  Traditional approach prediction future traject...\n"
     ]
    }
   ],
   "source": [
    "###### Directly using the TINY preprocessed data set file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filePath = 'C:\\\\Users\\\\Dell\\\\Desktop\\\\My Coding\\\\Kaggle CS dataset\\\\Tiny_processed_DataSet.csv'\n",
    "df = pd.read_csv(filePath)\n",
    "\n",
    "# Set the display width to a large number to prevent line wrapping\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"1st 5 lines in the datset \\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151ae963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.40.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\dell\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "   ---------------------------------------- 0.0/227.1 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/227.1 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/227.1 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 61.4/227.1 kB 544.7 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 81.9/227.1 kB 512.0 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 92.2/227.1 kB 476.3 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 92.2/227.1 kB 476.3 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 92.2/227.1 kB 476.3 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/227.1 kB 344.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/227.1 kB 344.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/227.1 kB 344.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/227.1 kB 344.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/227.1 kB 344.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/227.1 kB 344.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/227.1 kB 344.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 112.6/227.1 kB 344.8 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 122.9/227.1 kB 167.6 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 122.9/227.1 kB 167.6 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 122.9/227.1 kB 167.6 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 122.9/227.1 kB 167.6 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 122.9/227.1 kB 167.6 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 143.4/227.1 kB 142.1 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 143.4/227.1 kB 142.1 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 163.8/227.1 kB 151.3 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 174.1/227.1 kB 154.3 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 204.8/227.1 kB 172.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 227.1/227.1 kB 185.0 kB/s eta 0:00:00\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.0.0\n",
      "    Uninstalling sentence-transformers-3.0.0:\n",
      "      Successfully uninstalled sentence-transformers-3.0.0\n",
      "Successfully installed sentence-transformers-3.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "######## Embeddings using SBERT\n",
    "!pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0126dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######## Embeddings using SBERT\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load SBERT model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Function to encode sentences in a DataFrame column and return embeddings\n",
    "def encode_sentences(df, column_name):\n",
    "    embeddings_list = []\n",
    "    for paragraph in df[column_name]:\n",
    "        # Tokenize paragraph into sentences\n",
    "        sentences = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "        # Encode each sentence using SBERT model\n",
    "        sentence_embeddings = model.encode(sentences)\n",
    "        embeddings_list.append(sentence_embeddings)\n",
    "    return embeddings_list\n",
    "\n",
    "# Encode sentences in the 'Text' column\n",
    "embeddings_list = encode_sentences(df, 'singularized_abstract')\n",
    "\n",
    "\n",
    "# Save embeddings list to a CSV file\n",
    "import csv\n",
    "with open('Tiny_sentnceEmbeddings.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for embedding_row in embeddings_list:\n",
    "        writer.writerow(embedding_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c026ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
